{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dabcd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 14:24:07.345975: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:24:07.480326: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 14:24:07.480434: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 14:24:07.503066: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 14:24:07.552324: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:24:07.554089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 14:24:08.906679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/feynman/home/dap/lcs/ec270266/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wf_psf as wf_psf\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed, cpu_count, parallel_backend\n",
    "from wf_psf.utils.utils import zernike_generator\n",
    "from wf_psf.sims.SimPSFToolkit import SimPSFToolkit\n",
    "from wf_psf.psf_models.tf_layers import TF_poly_Z_field\n",
    "\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17b37d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "wf_psf_dir = '/feynman/work/dap/lcs/ec270266/wf-psf/'\n",
    "output_dir = '/feynman/work/dap/lcs/ec270266/output/'\n",
    "# SED folder path\n",
    "# SED_path = '/feynman/work/dap/lcs/ec270266/wf-psf/data/SEDs/save_SEDs/'\n",
    "# SED_path = '/feynman/home/dap/lcs/as274094/work/wf-psf/data/SEDs/save_SEDs/'\n",
    "SED_path = wf_psf_dir+'data/SEDs/save_SEDs/'\n",
    "\n",
    "# Output saving path (in node05 of candide or $WORK space on feynman)\n",
    "# output_folder = '/feynman/work/dap/lcs/ec270266/output/interp_SEDs/'\n",
    "output_folder = output_dir+'psf_dataset/'\n",
    "\n",
    "# Reference dataset PATH\n",
    "# reference_data = '../interp_SED_data/reference_dataset/'\n",
    "reference_data = wf_psf_dir+'data/coherent_euclid_dataset/'\n",
    "ref_train = 'train_Euclid_res_2000_TrainStars_id_001.npy'\n",
    "ref_test  = 'test_Euclid_res_id_001.npy'\n",
    "selected_id_SED_path = 'selected_id_SED.npy'\n",
    "\n",
    "# Number of cpus to use for parallelization\n",
    "#n_cpus = 512 #verify that it doesn't reach the N of actual CPUs\n",
    "n_cpus = 24\n",
    "\n",
    "# Save output prints to logfile\n",
    "old_stdout = sys.stdout\n",
    "log_file = open(output_folder + 'output.log','w')\n",
    "sys.stdout = log_file\n",
    "print('Starting the log file.')\n",
    "\n",
    "# Dataset ID\n",
    "dataset_id = 1\n",
    "dataset_id_str = '%03d'%(dataset_id)\n",
    "\n",
    "# This list must be in order from bigger to smaller\n",
    "n_star_list = [52]\n",
    "n_test_stars = 20\n",
    "# Total stars\n",
    "n_stars = n_star_list[0] + n_test_stars\n",
    "# Max train stars\n",
    "tot_train_stars = n_star_list[0]\n",
    "\n",
    "# Parameters\n",
    "d_max = 2\n",
    "max_order = 45\n",
    "x_lims = [0, 1e3]\n",
    "y_lims = [0, 1e3]\n",
    "grid_points = [4, 4]\n",
    "n_bins = 100 \n",
    "auto_init = False\n",
    "verbose = True\n",
    "\n",
    "oversampling_rate = 3.\n",
    "output_Q = 3.\n",
    "\n",
    "max_wfe_rms = 0.1\n",
    "output_dim = 32\n",
    "LP_filter_length = 2\n",
    "euclid_obsc = True\n",
    "\n",
    "# Values for getting 3xEuclid_resolution PSFs outputs.\n",
    "original_out_Q = output_Q\n",
    "original_out_dim = output_dim\n",
    "super_out_Q = 1\n",
    "super_out_res = 64\n",
    "\n",
    "# Desired WFE resolutions\n",
    "WFE_resolutions = [256]\n",
    "\n",
    "print('\\nInit dataset generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0cd8d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "#zernikes_multires = []\n",
    "sim_PSF_toolkit_multires = []\n",
    "#gen_poly_fieldPSF_multires = []\n",
    "\n",
    "for i, pupil_diameter_ in tqdm(enumerate(WFE_resolutions)):\n",
    "\n",
    "    # # Generate Zernike maps in max resolution\n",
    "    # zernikes_multires.append(\n",
    "    #     zernike_generator(\n",
    "    #         n_zernikes=max_order,\n",
    "    #         wfe_dim=pupil_diameter_\n",
    "    #     )\n",
    "    # )\n",
    "    \n",
    "    # Initialize PSF simulator for each cpu available \n",
    "    # (no euclid obscurations and wfr_rms init)\n",
    "    packed_PSFToolkit = [SimPSFToolkit(\n",
    "        #zernikes_multires[i],\n",
    "        max_order=max_order,\n",
    "        max_wfe_rms=max_wfe_rms,\n",
    "        oversampling_rate=oversampling_rate,\n",
    "        output_Q=output_Q,\n",
    "        output_dim=output_dim,\n",
    "        pupil_diameter=pupil_diameter_,\n",
    "        euclid_obsc=euclid_obsc,\n",
    "        LP_filter_length=LP_filter_length\n",
    "    ) for j in range(n_cpus)]\n",
    "    sim_PSF_toolkit_multires.append(packed_PSFToolkit)\n",
    "\n",
    "    # Initialize one PSF field for each resolution\n",
    "    # packed_polyField_PSF = [wf_psf.GenPolyFieldPSF(\n",
    "    #     sim_PSF_toolkit_multires[i][j],\n",
    "    #     d_max=d_max,\n",
    "    #     grid_points=grid_points,\n",
    "    #     max_order=max_order,\n",
    "    #     x_lims=x_lims,\n",
    "    #     y_lims=y_lims,\n",
    "    #     n_bins=n_bins,\n",
    "    #     lim_max_wfe_rms=max_wfe_rms,\n",
    "    #     auto_init=auto_init,\n",
    "    #     verbose=verbose\n",
    "    # ) for j in range(n_cpus)]\n",
    "    # gen_poly_fieldPSF_multires.append(packed_polyField_PSF)\n",
    "    \n",
    "\n",
    "# # Dummy SimPSFToolkit to init obscurations\n",
    "# init_toolkit = []\n",
    "# init_polyField = []\n",
    "# for i, pupil_diameter_ in enumerate(WFE_resolutions):\n",
    "#     init_toolkit.append( wf_psf.SimPSFToolkit(\n",
    "#         zernikes_multires[i], max_order=max_order, max_wfe_rms=max_wfe_rms, oversampling_rate=oversampling_rate,\n",
    "#         output_Q=output_Q, output_dim=output_dim, pupil_diameter=pupil_diameter_, euclid_obsc=euclid_obsc,\n",
    "#         LP_filter_length=LP_filter_length) )\n",
    "#     init_polyField.append( wf_psf.GenPolyFieldPSF(init_toolkit[i], d_max=d_max,\n",
    "#         grid_points=grid_points, max_order=max_order,\n",
    "#         x_lims=x_lims, y_lims=y_lims, n_bins=n_bins,\n",
    "#         lim_max_wfe_rms=max_wfe_rms, auto_init=True, verbose=verbose))\n",
    "\n",
    "# # Share C_poly coefficients throughout all the different resolution models\n",
    "# for i in range(len(gen_poly_fieldPSF_multires)):\n",
    "#     for j in range(n_cpus):\n",
    "#         gen_poly_fieldPSF_multires[i][j].set_C_poly(init_polyField[0].C_poly)\n",
    "#         gen_poly_fieldPSF_multires[i][j].set_WFE_RMS(init_polyField[0].WFE_RMS)\n",
    "#         gen_poly_fieldPSF_multires[i][j].sim_psf_toolkit.obscurations = init_toolkit[i].obscurations\n",
    "\n",
    "Z_field = TF_poly_Z_field(\n",
    "    x_lims=x_lims,\n",
    "    y_lims=y_lims,\n",
    "    n_zernikes=max_order,\n",
    "    d_max=d_max,)\n",
    "\n",
    "# Load the SEDs\n",
    "stellar_SEDs = np.load(SED_path + 'SEDs.npy', allow_pickle=True)\n",
    "stellar_lambdas = np.load(SED_path + 'lambdas.npy', allow_pickle=True)\n",
    "\n",
    "# Load reference dataset\n",
    "train_dataset_ref = np.load(reference_data+ref_train, allow_pickle=True)[()]\n",
    "test_dataset_ref = np.load(reference_data+ref_test, allow_pickle=True)[()]\n",
    "\n",
    "'''\n",
    "# Load all the stars positions\n",
    "pos_np = np.vstack((train_dataset_ref['positions'],test_dataset_ref['positions']))\n",
    "\n",
    "# Assign preselected SEDs\n",
    "selected_id_SED = np.load(reference_data+'selected_id_SED.npy', allow_pickle=True)\n",
    "SED_list = []\n",
    "for it in range(n_stars):\n",
    "    concat_SED_wv = np.concatenate((\n",
    "        stellar_lambdas.reshape(-1,1),\n",
    "        stellar_SEDs[selected_id_SED[it],:].reshape(-1,1)\n",
    "    ), axis=1)\n",
    "    SED_list.append(concat_SED_wv)\n",
    "'''\n",
    "    \n",
    "\n",
    "# Choose the locations randomly\n",
    "pos_np = np.random.rand(n_stars, 2)\n",
    "\n",
    "pos_np[:,0] = pos_np[:,0]*(x_lims[1] - x_lims[0]) + x_lims[0]\n",
    "pos_np[:,1] = pos_np[:,1]*(y_lims[1] - y_lims[0]) + y_lims[0]    \n",
    "\n",
    "# Select random SEDs\n",
    "SED_list = []\n",
    "SED_id_list = []\n",
    "for it in range(n_stars):\n",
    "    selected_id_SED = np.random.randint(low=0, high=13)\n",
    "    concat_SED_wv = np.concatenate((\n",
    "        stellar_lambdas.reshape(-1,1),\n",
    "        stellar_SEDs[selected_id_SED,:].reshape(-1,1)), axis=1)\n",
    "    SED_id_list.append(selected_id_SED)\n",
    "    SED_list.append(concat_SED_wv)\n",
    "        \n",
    "\n",
    "\n",
    "# Load and assign the C_poly matrix\n",
    "C_poly = train_dataset_ref['C_poly']\n",
    "Z_field.assign_coeff_matrix(C_poly)\n",
    "\n",
    "# for i in range(len(gen_poly_fieldPSF_multires)):\n",
    "#     for j in range(n_cpus):\n",
    "#         gen_poly_fieldPSF_multires[i][j].set_C_poly(C_poly)\n",
    "\n",
    "print('\\nStar positions selected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95821b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fff9daa13a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "star_id = 4\n",
    "sim_PSF_toolkit_multires[0][0].set_z_coeffs(Z_field(pos_np)[star_id,:,0,0].numpy().tolist())\n",
    "psf_test = sim_PSF_toolkit_multires[0][0].generate_poly_PSF(SED_list[star_id], n_bins)\n",
    "plt.imshow(psf_test,cmap='gist_stern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed4557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 14:33:25.044852: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:25.081032: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 14:33:25.081083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 14:33:25.082302: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 14:33:25.088647: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:25.088866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 14:33:25.418152: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:25.448530: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 14:33:25.448588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 14:33:25.449368: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 14:33:25.454420: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:25.454651: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 14:33:25.895896: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:25.926211: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 14:33:25.926272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 14:33:25.927061: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 14:33:25.932063: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:25.932288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 14:33:26.296208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-11 14:33:26.297380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-11 14:33:26.403859: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:26.439724: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 14:33:26.439788: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 14:33:26.440725: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 14:33:26.446794: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:26.447052: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 14:33:26.927822: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:26.962194: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 14:33:26.962247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 14:33:26.963167: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 14:33:26.968944: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:26.969159: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 14:33:27.045293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-11 14:33:27.531522: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:27.564452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-11 14:33:27.575143: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 14:33:27.575210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 14:33:27.576283: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 14:33:27.583291: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:27.583574: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/feynman/home/dap/lcs/ec270266/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/feynman/home/dap/lcs/ec270266/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "2023-12-11 14:33:28.006037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/feynman/home/dap/lcs/ec270266/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "2023-12-11 14:33:28.719932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/feynman/home/dap/lcs/ec270266/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/feynman/home/dap/lcs/ec270266/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/feynman/home/dap/lcs/ec270266/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "2023-12-11 14:33:53.679752: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:53.712814: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 14:33:53.712877: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 14:33:53.714135: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 14:33:53.720173: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-11 14:33:53.720403: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 14:33:54.771623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/feynman/home/dap/lcs/ec270266/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#######################################\n",
    "#            PARALELLIZED             #\n",
    "#######################################\n",
    "\n",
    "# Total number of stars\n",
    "n_procs = n_stars*len(WFE_resolutions)\n",
    "\n",
    "# Print some info\n",
    "cpu_info = ' - Number of available CPUs: {}'.format(cpu_count())\n",
    "cpu_use = ' - Number of selected CPUs: {}'.format(n_cpus)\n",
    "proc_info = ' - Total number of processes: {}'.format(n_procs)\n",
    "print(cpu_info)\n",
    "print(cpu_use)\n",
    "print(proc_info)\n",
    "\n",
    "# Generate star list\n",
    "star_id_list = [id_ for id_ in range(n_stars)]\n",
    "\n",
    "\n",
    "# Function to get (i,j) from id\n",
    "def unwrap_id(id, n_cpus):\n",
    "    i = int(id/n_cpus)\n",
    "    j = int(id - i * n_cpus)\n",
    "    return i, j\n",
    "\n",
    "def print_status(star_id, i, j):\n",
    "    print('\\nStar ' +str(star_id)+ ' done!' + '   index=('+str(i)+','+str(j)+')')\n",
    "\n",
    "# Get batches from a list\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "# Function to get one PSF\n",
    "def simulate_star(star_id, sim_PSF_toolkit_multires,i):\n",
    "    i_,j_ = unwrap_id(star_id, n_cpus)\n",
    "    _zernike = Z_field(pos_np)[star_id,:,0,0].numpy().tolist()\n",
    "    sim_PSF_toolkit_multires[i][j_].set_z_coeffs(_zernike)\n",
    "    _psf = sim_PSF_toolkit_multires[i][j_].generate_poly_PSF(SED_list[star_id], n_bins)\n",
    "    # _psf, _zernike, _ = sim_PSF_toolkit_multires[i][j_].generate_poly_PSF(\n",
    "    #     xv_flat=pos_np[star_id, 0],\n",
    "    #     yv_flat=pos_np[star_id, 1],\n",
    "    #     SED=SED_list[star_id]\n",
    "    # )\n",
    "    # Change output parameters to get the super resolved PSF\n",
    "    sim_PSF_toolkit_multires[i][j_].output_Q = super_out_Q\n",
    "    sim_PSF_toolkit_multires[i][j_].output_dim = super_out_res\n",
    "    super_psf = sim_PSF_toolkit_multires[i][j_].generate_poly_PSF(SED_list[star_id], n_bins)\n",
    "    # super_psf, _, _ = gen_poly_fieldPSF_multires[i][j_].get_poly_PSF(\n",
    "    #     xv_flat=pos_np[star_id, 0],\n",
    "    #     yv_flat=pos_np[star_id, 1],\n",
    "    #     SED=SED_list[star_id]\n",
    "    # )\n",
    "    # Put back original parameters\n",
    "    sim_PSF_toolkit_multires[i][j_].output_Q = original_out_Q\n",
    "    sim_PSF_toolkit_multires[i][j_].output_dim = original_out_dim\n",
    "    #print_status(star_id, i, star_id)\n",
    "    return (star_id, _psf, _zernike, super_psf)\n",
    "\n",
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "zernike_coef_multires = []\n",
    "poly_psf_multires = []\n",
    "index_multires = []\n",
    "super_psf_multires = []\n",
    "\n",
    "for i in range(len(WFE_resolutions)):\n",
    "    index_i_list = []\n",
    "    psf_i_list = []\n",
    "    z_coef_i_list = []\n",
    "    super_psf_i_list = []\n",
    "    for batch in chunker(star_id_list, n_cpus):\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "            results = Parallel(n_jobs=n_cpus, verbose=100)(delayed(simulate_star)(_star_id, sim_PSF_toolkit_multires,i)\n",
    "                                                for _star_id in batch)\n",
    "        index_batch,psf_batch,z_coef_batch,super_psf_batch = zip(*results)\n",
    "        index_i_list.extend(index_batch)\n",
    "        psf_i_list.extend(psf_batch)\n",
    "        z_coef_i_list.extend(z_coef_batch)\n",
    "        super_psf_i_list.extend(super_psf_batch)\n",
    "\n",
    "    index_multires.append(np.array(index_i_list) )\n",
    "    poly_psf_multires.append(np.array( psf_i_list)) \n",
    "    zernike_coef_multires.append(np.array(z_coef_i_list))\n",
    "    super_psf_multires.append(np.array(super_psf_i_list))\n",
    "\n",
    "end_time = time.time()\n",
    "print('\\nAll stars generated in '+ str(end_time-start_time) +' seconds')\n",
    "\n",
    "#######################################\n",
    "#            END PARALLEL             #\n",
    "#######################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a25ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add noise to generated train star PSFs and save datasets\n",
    "\n",
    "# SNR varying randomly from 50 to 400 - shared over all WFE resolutions\n",
    "rand_SNR_train = (np.random.rand(tot_train_stars) * 350) + 50\n",
    "# Copy the training stars\n",
    "train_stars = np.copy(np.array(poly_psf_multires[0])[:tot_train_stars, :, :])\n",
    "# Add Gaussian noise to the observations\n",
    "noisy_train_stars = np.stack([wf_psf.utils.utils.add_noise(_im, desired_SNR=_SNR) \n",
    "                              for _im, _SNR in zip(train_stars, rand_SNR_train)], axis=0)\n",
    "# Generate Gaussian noise patterns to be shared over all datasets (but not every star)\n",
    "noisy_train_patterns = noisy_train_stars - train_stars\n",
    "\n",
    "\n",
    "# Add noise to generated test star PSFs and save datasets\n",
    "\n",
    "# SNR varying randomly from 20 to 400 - shared over all WFE resolutions\n",
    "rand_SNR_test = (np.random.rand(n_test_stars) * 380) + 20\n",
    "# Copy the test stars\n",
    "test_stars = np.copy(np.array(poly_psf_multires[0])[tot_train_stars:, :, :])\n",
    "# Add Gaussian noise to the observations\n",
    "noisy_test_stars = np.stack([wf_psf.utils.utils.add_noise(_im, desired_SNR=_SNR) \n",
    "                              for _im, _SNR in zip(train_stars, rand_SNR_test)], axis=0)\n",
    "# Generate Gaussian noise patterns to be shared over all datasets (but not every star)\n",
    "noisy_test_patterns = noisy_test_stars - test_stars\n",
    "\n",
    "\n",
    "WFE_res_id = 0\n",
    "\n",
    "# Generate datasets for every WFE resolution\n",
    "for poly_psf_np, zernike_coef_np, super_psf_np in zip(poly_psf_multires, zernike_coef_multires, super_psf_multires):\n",
    "    \n",
    "    # Generate numpy array from the SED list\n",
    "    SED_np = np.array(SED_list)\n",
    "\n",
    "    # Add same noise dataset to each WFE-resolution dataset\n",
    "    noisy_train_stars = np.copy(poly_psf_np[:tot_train_stars, :, :]) + noisy_train_patterns\n",
    "    noisy_test_stars = np.copy(poly_psf_np[tot_train_stars:, :, :]) + noisy_test_patterns\n",
    "\n",
    "    # Save only one test dataset\n",
    "    # Build param dicitionary\n",
    "    dataset_params = {\n",
    "        'd_max':d_max,\n",
    "        'max_order':max_order,\n",
    "        'x_lims':x_lims,\n",
    "        'y_lims':y_lims,\n",
    "        'grid_points':grid_points,\n",
    "        'n_bins':n_bins,\n",
    "        'max_wfe_rms':max_wfe_rms,\n",
    "        'oversampling_rate':oversampling_rate,\n",
    "        'output_Q':output_Q,\n",
    "        'output_dim':output_dim,\n",
    "        'LP_filter_length':LP_filter_length,\n",
    "        'pupil_diameter':WFE_resolutions[WFE_res_id],\n",
    "        'euclid_obsc':euclid_obsc,\n",
    "        'n_stars':n_test_stars\n",
    "    }\n",
    "\n",
    "    # Save dataset C coefficient matrix (reproductible dataset)\n",
    "    C_poly = Z_field.get_coeff_matrix()\n",
    "\n",
    "    test_psf_dataset = {\n",
    "        'stars' : poly_psf_np[tot_train_stars:, :, :],\n",
    "        'noisy_stars': noisy_test_stars,\n",
    "        'super_res_stars' : super_psf_np[tot_train_stars:, :, :],\n",
    "        'positions' : pos_np[tot_train_stars:, :],\n",
    "        'SEDs' : SED_np[tot_train_stars:, :, :],\n",
    "        'zernike_coef' : zernike_coef_np[tot_train_stars:, :],\n",
    "        'C_poly' : C_poly,\n",
    "        'parameters': dataset_params,\n",
    "        'SED_ids':SED_id_list[tot_train_stars:],\n",
    "        'SNR': rand_SNR_test\n",
    "    }\n",
    "\n",
    "    np.save(\n",
    "        output_folder + 'test_Euclid_res_' + str(n_test_stars) + '_TestStars_id_' + dataset_id_str + 'GT_100_bins.npy',\n",
    "        test_psf_dataset,\n",
    "        allow_pickle=True\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Save the different train datasets\n",
    "    for it_glob in range(len(n_star_list)):\n",
    "\n",
    "        n_train_stars = n_star_list[it_glob]\n",
    "\n",
    "        # Build param dicitionary\n",
    "        dataset_params = {\n",
    "            'd_max':d_max,\n",
    "            'max_order':max_order,\n",
    "            'x_lims':x_lims,\n",
    "            'y_lims':y_lims,\n",
    "            'grid_points':grid_points,\n",
    "            'n_bins':n_bins,\n",
    "            'max_wfe_rms':max_wfe_rms,\n",
    "            'oversampling_rate':oversampling_rate,\n",
    "            'output_Q':output_Q,\n",
    "            'output_dim':output_dim,\n",
    "            'LP_filter_length':LP_filter_length,\n",
    "            'pupil_diameter':WFE_resolutions[WFE_res_id],\n",
    "            'euclid_obsc':euclid_obsc,\n",
    "            'n_stars':n_train_stars\n",
    "        }\n",
    "\n",
    "        train_psf_dataset = {\n",
    "            'stars' : poly_psf_np[:n_train_stars, :, :],\n",
    "            'noisy_stars': noisy_train_stars[:n_train_stars, :, :],\n",
    "            'super_res_stars' : super_psf_np[:n_train_stars, :, :],\n",
    "            'positions' : pos_np[:n_train_stars, :],\n",
    "            'SEDs' : SED_np[:n_train_stars, :, :],\n",
    "            'zernike_coef' : zernike_coef_np[:n_train_stars, :],\n",
    "            'C_poly' : C_poly,\n",
    "            'parameters': dataset_params,\n",
    "            'SED_ids' : SED_id_list[:n_train_stars],\n",
    "            'SNR': rand_SNR_train\n",
    "        }\n",
    "\n",
    "\n",
    "        np.save(\n",
    "            output_folder + 'train_Euclid_res_' + str(n_train_stars) + '_TrainStars_id_' + dataset_id_str + 'GT_100_bins.npy',\n",
    "            train_psf_dataset,\n",
    "            allow_pickle=True\n",
    "        )\n",
    "\n",
    "    # Next desired resolution   \n",
    "    WFE_res_id += 1\n",
    "\n",
    "print('\\nDone!')\n",
    "\n",
    "# Close log file\n",
    "sys.stdout = old_stdout\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01241fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
